{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeremiah Mubiru and James Telzrow <br>\n",
    "2024-05-06 <br>\n",
    "CSDS490 <br>\n",
    "Experimentation/Exploratory Project \n",
    "\n",
    "To run this notebook, you must install:\n",
    "* BeautifulSoup4\n",
    "* OpenCV-Python (Possibly OpenCV-Python-Headless)\n",
    "* Requests\n",
    "* ScikitLearn\n",
    "\n",
    "This notebook can be used to create a dataset, or it can use an existing one (available in Google Drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "import random\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the following cells, we will demonstrate a fast an efficient way of \n",
    "# determining the state from which a license plate originates. We do \n",
    "# this by computing the histogram of such images, and using the resulting\n",
    "# vectors to map the image into a high-dimensional Euclidean space.\n",
    "# The theory is that visually similar license plates (i.e. those issued by\n",
    "# the same state) will have similar histograms, and thus will be mapped\n",
    "# into the same region in Euclidean space.\n",
    "# Thus by creating a point cloud using a large training dataset, we can \n",
    "# apply a k-nearest-neighbors approach to determine the state of origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we use acme.com's license plate maker website to create an \n",
    "# image of a specific type of license plate for the specified \n",
    "# state, with the specified text.\n",
    "# Usually, the type of plate (the value of the \"plate\" argument) \n",
    "# is the year in which it was issued.\n",
    "# However, some states issue \"special edition\" license plates \n",
    "# to raise awareness for a cause or commemorate an event, so this\n",
    "# can sometimes accept values like \"Cure Cancer\" or \"Challenger\".\n",
    "# This returns the image as bytes.\n",
    "\n",
    "def get_plate_image(state, plate, text):\n",
    "    request_url = 'https://www.acme.com/licensemaker/'\n",
    "    response_containing_page = requests.get(\n",
    "        request_url + 'licensemaker.cgi',\n",
    "        params = {\n",
    "            'state': state,\n",
    "            'plate': plate,\n",
    "            'text': text,\n",
    "        },\n",
    "    )\n",
    "    parsed_page = BeautifulSoup(response_containing_page.text)\n",
    "    image_link = parsed_page.find('a', href=True)['href']\n",
    "    response_containing_image = requests.get(\n",
    "        request_url + image_link\n",
    "    )\n",
    "    image_bytes = response_containing_image.content\n",
    "    return image_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# License plate designs change over time; for brevity we don't consider \n",
    "# all of them here.\n",
    "# Here, we list all 50 states, and the particular years of plates that we\n",
    "# want to consider for each state.\n",
    "\n",
    "states = [\n",
    "    'Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado',\n",
    "    'Connecticut', 'Delaware', 'Florida', 'Georgia', 'Hawaii', 'Idaho',\n",
    "    'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana',\n",
    "    'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota',\n",
    "    'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada',\n",
    "    'New Hampshire', 'New Jersey', 'New Mexico', 'New York',\n",
    "    'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon',\n",
    "    'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota',\n",
    "    'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington',\n",
    "    'West Virginia', 'Wisconsin', 'Wyoming'\n",
    "]\n",
    "years = {\n",
    "    'Alabama': [\n",
    "        '2002'\n",
    "    ],\n",
    "    'Alaska': [\n",
    "        '1982'\n",
    "    ],\n",
    "    'Arizona': [\n",
    "        '1996'\n",
    "    ],\n",
    "    'Arkansas': [\n",
    "        '1996'\n",
    "    ],\n",
    "    'California': [\n",
    "        '1998'\n",
    "    ],\n",
    "    'Colorado': [\n",
    "        '2000'\n",
    "    ],\n",
    "    'Connecticut': [\n",
    "        '1987'\n",
    "    ],\n",
    "    'Colorado': [\n",
    "        '2000'\n",
    "    ],\n",
    "    'Delaware': [\n",
    "        '1970'\n",
    "    ],\n",
    "    'Florida': [\n",
    "        '1997'\n",
    "    ],\n",
    "    'Georgia': [\n",
    "        '1998'\n",
    "    ],\n",
    "    'Colorado': [\n",
    "        '2000'\n",
    "    ],\n",
    "    'Hawaii': [\n",
    "        '1991'\n",
    "    ],\n",
    "    'Idaho': [\n",
    "        '1997'\n",
    "    ],\n",
    "    'Colorado': [\n",
    "        '2000'\n",
    "    ],\n",
    "    'Illinois': [\n",
    "        '2002'\n",
    "    ],\n",
    "    'Indiana': [\n",
    "        '1999'\n",
    "    ],\n",
    "    'Iowa': [\n",
    "        '1997'\n",
    "    ],\n",
    "    'Kansas': [\n",
    "        '1995'\n",
    "    ],\n",
    "    'Kentucky': [\n",
    "        '1997'\n",
    "    ],\n",
    "    'Louisiana': [\n",
    "        '1994'\n",
    "    ],\n",
    "    'Maine': [\n",
    "        '1999'\n",
    "    ],\n",
    "    'Maryland': [\n",
    "        '1986'\n",
    "    ],\n",
    "    'Massachusetts': [\n",
    "        '1988'\n",
    "    ],\n",
    "    'Michigan': [\n",
    "        '1983'\n",
    "    ],\n",
    "    'Minnesota': [\n",
    "        '1993'\n",
    "    ],\n",
    "    'Mississippi': [\n",
    "        '1997'\n",
    "    ],\n",
    "    'Missouri': [\n",
    "        '1998'\n",
    "    ],\n",
    "    'Montana': [\n",
    "        '1991'\n",
    "    ],\n",
    "    'Nebraska': [\n",
    "        '1993'\n",
    "    ],\n",
    "    'Nevada': [\n",
    "        '1987'\n",
    "    ],\n",
    "    'New Hampshire': [\n",
    "        '1999'\n",
    "    ],\n",
    "    'New Jersey': [\n",
    "        '1993'\n",
    "    ],\n",
    "    'New Mexico': [\n",
    "        '1991'\n",
    "    ],\n",
    "    'New York': [\n",
    "        '1986'\n",
    "    ],\n",
    "    'North Carolina': [\n",
    "        '1982'\n",
    "    ],\n",
    "    'North Dakota': [\n",
    "        '1993'\n",
    "    ],\n",
    "    'Ohio': [\n",
    "        '1997'\n",
    "    ],\n",
    "    'Oklahoma': [\n",
    "        '1994'\n",
    "    ],\n",
    "    'Oregon': [\n",
    "        '1988'\n",
    "    ],\n",
    "    'Pennsylvania': [\n",
    "        '2000'\n",
    "    ],\n",
    "    'Rhode Island': [\n",
    "        '1996'\n",
    "    ],\n",
    "    'South Carolina': [\n",
    "        '1998'\n",
    "    ],\n",
    "    'South Dakota': [\n",
    "        '2000'\n",
    "    ],\n",
    "    'Tennessee': [\n",
    "        '2000'\n",
    "    ],\n",
    "    'Texas': [\n",
    "        '2000'\n",
    "    ],\n",
    "    'Utah': [\n",
    "        '1996'\n",
    "    ],\n",
    "    'Vermont': [\n",
    "        '1985'\n",
    "    ],\n",
    "    'Virginia': [\n",
    "        '1980'\n",
    "    ],\n",
    "    'Washington': [\n",
    "        '1998'\n",
    "    ],\n",
    "    'West Virginia': [\n",
    "        '1995'\n",
    "    ],\n",
    "    'Wisconsin': [\n",
    "        '1987'\n",
    "    ],\n",
    "    'Wyoming': [\n",
    "        '1992'\n",
    "    ],\n",
    "}\n",
    "plate_images = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create our dataset.\n",
    "\n",
    "# The number of plates from each state that will be in the dataset.\n",
    "number_of_plates_to_generate = 50\n",
    "# The number of characters on each plate\n",
    "plate_text_length = 7\n",
    "\n",
    "# Get the plate images from acme.com\n",
    "for state in states:\n",
    "    plate_images[state] = {}\n",
    "    for year in years[state]:\n",
    "        plate_images[state][year] = {}\n",
    "        for _ in range(0, number_of_plates_to_generate):\n",
    "            text = ''.join(random.choices(string.ascii_uppercase + string.digits, k=plate_text_length))\n",
    "            plate_image = get_plate_image(state, year, text)\n",
    "            plate_images[state][year][text] = plate_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a directory where the dataset will be saved\n",
    "image_directory = './images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset to disk\n",
    "for state in states:\n",
    "    for year in years[state]:\n",
    "        for plate_text in list(plate_images[state][year].keys()):\n",
    "            file_name = state + '_' + year + '_' + plate_text + '.jpg'\n",
    "            open(image_directory + file_name, 'wb').write(plate_images[state][year][plate_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every instance of this class represents a particular image in the dataset.\n",
    "class Labeled_Image:\n",
    "\n",
    "    def __init__(self, state, year, text, image, blue_histogram, green_histogram, red_histogram):\n",
    "        self.state = state\n",
    "        self.year = year\n",
    "        self.text = text\n",
    "        self.image = image\n",
    "        self.blue_histogram = blue_histogram\n",
    "        self.green_histogram = green_histogram\n",
    "        self.red_histogram = red_histogram\n",
    "\n",
    "# Each histogram has 32 bins, and intensity values can range between 0 and 256.\n",
    "number_of_bins = 32\n",
    "possible_values = [0, 256]\n",
    "\n",
    "labeled_images = []\n",
    "\n",
    "# Load the dataset from disk, and compute the histograms for each color channel of each image.\n",
    "# In this way, we map images to points in R^{number_of_bins * 3}\n",
    "for image_file in listdir(image_directory):\n",
    "    image_file_name = image_file.split('.')[0]\n",
    "    state, year, text = image_file_name.split('_')\n",
    "    image = cv2.imread(image_directory + image_file, cv2.IMREAD_COLOR)\n",
    "\n",
    "    image_channels = cv2.split(image)\n",
    "    blue_histogram = cv2.calcHist([image_channels[0]], [0], None, [number_of_bins], possible_values)\n",
    "    green_histogram = cv2.calcHist([image_channels[1]], [0], None, [number_of_bins], possible_values)\n",
    "    red_histogram = cv2.calcHist([image_channels[2]], [0], None, [number_of_bins], possible_values)\n",
    "\n",
    "    labeled_image = Labeled_Image(\n",
    "        state = state,\n",
    "        year = year,\n",
    "        text = text,\n",
    "        image = image,\n",
    "        blue_histogram = blue_histogram,\n",
    "        green_histogram = green_histogram,\n",
    "        red_histogram = red_histogram,\n",
    "    )\n",
    "\n",
    "    labeled_images.append(labeled_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that maps state names to the corresponding integer \n",
    "# when states are organized in zero-indexed alphabetical order\n",
    "def get_numerical_state_label(state):\n",
    "    return states.index(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we arrange these images into a numpy array so we can perform predictions using scikit learn, and assign them integer labels\n",
    "\n",
    "# Every row in this array corresponds to an image.\n",
    "# The first \"number_of_bins\" columns correspond to blue histogram values, the second correspond to green histogram values, and the third correspond to red histogram values.\n",
    "# The final column is the label, an integer indicating which state the plate is from.\n",
    "\n",
    "labeled_imgs_array = np.zeros((len(labeled_images), (3 * number_of_bins) + 1))\n",
    "\n",
    "for index in range(0, len(labeled_images)):\n",
    "    labeled_image = labeled_images[index]\n",
    "    labeled_imgs_array[index, 0:number_of_bins] = labeled_image.blue_histogram.flatten()\n",
    "    labeled_imgs_array[index, number_of_bins:2*number_of_bins] = labeled_image.green_histogram.flatten()\n",
    "    labeled_imgs_array[index, 2*number_of_bins:3*number_of_bins] = labeled_image.red_histogram.flatten()\n",
    "    labeled_imgs_array[index, 3*number_of_bins] = get_numerical_state_label(labeled_image.state)\n",
    "\n",
    "# Next, we normalize the histograms, so that the sum of the values for each bin within a particular channel equal one.\n",
    "blue_channel_sums, green_channel_sums, red_channel_sums = [labeled_imgs_array[:, x*number_of_bins:(x + 1)*number_of_bins].sum(axis = 1) for x in range(0, 3)]\n",
    "nrmlzd_lb_img_arr = np.copy(labeled_imgs_array)\n",
    "nrmlzd_lb_img_arr[:, 0:number_of_bins] /= blue_channel_sums[:, np.newaxis]\n",
    "nrmlzd_lb_img_arr[:, number_of_bins:2*number_of_bins] /= green_channel_sums[:, np.newaxis]\n",
    "nrmlzd_lb_img_arr[:, 2*number_of_bins:3*number_of_bins] /= red_channel_sums[:, np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we split thee dataset into training and tests sets, to train \n",
    "# and evaluate our classifier\n",
    "training_imgs, test_imgs, train_labels, test_labels = train_test_split(\n",
    "    nrmlzd_lb_img_arr[:, :-1], nrmlzd_lb_img_arr[:, -1], test_size = 0.875\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9776051188299817"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next, we actually train and score our classifier.\n",
    "# Even when trained on only 12.5 percent of the available\n",
    "# data, this approach is able to achieve 97.7 percent accuracy.\n",
    "# Accuracy increases significantly if the training dataset is \n",
    "# larger.\n",
    "classifier = KNeighborsClassifier(n_neighbors = 3)\n",
    "classifier.fit(training_imgs, train_labels)\n",
    "\n",
    "classifier.score(test_imgs, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
